{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ziZxrPveyyb-"
   },
   "source": [
    "# AIP2 Lab Session #5:\n",
    "# Titanic: Machine Learning from Disaster!\n",
    "### **2020.10.28**<br/>\n",
    "---\n",
    "\n",
    "<br/>\n",
    "\n",
    "***Library***\n",
    "\n",
    "- Numpy\n",
    "- Pandas\n",
    "- Sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_0V9WyJ5yyb_"
   },
   "source": [
    "![Sto%CC%88wer_Titanic.jpg](attachment:Sto%CC%88wer_Titanic.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r_dR7L1hyycA",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This is the library to use for this project.\n",
    "# It must be executed before the next cell execution.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pS8O9REDyycD"
   },
   "source": [
    "## 1. Data analysis\n",
    "$\\quad$Before applying the Preprocessing and Machine Learning algorithm, it is important to first understand how the given data is organized. The data presented by this Kaggle Project contains the following information.\n",
    "\n",
    "<br>\n",
    "$\\quad$Let's take a look at the description and code below to see how the above information is stored in the data and how the data is distributed.\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xFQhc2ncyycD",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#  Read Data\n",
    "train_data = pd.read_csv('train.csv');\n",
    "test_data = pd.read_csv('test.csv');\n",
    "\n",
    "#print(train_data[[\"Age\"]].hist(bins=20))\n",
    "#print(train_data[[\"Fare\"]].hist(bins=50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IsYWDpVCyycG"
   },
   "source": [
    "$\\quad$First, it reads the data. The data includes train.csv for training and test.csv for testing. Use the read_csv function of the pandas library to read both data. The imported data is specified as train_data and test_data, respectively.\n",
    "<br>\n",
    "\n",
    "$\\quad$It is necessary to check how the above information is stored in the read data. Let's run the code below to check out the parts of train.csv and test.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JfeHXKVJyycK",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read first 5 of train_data\n",
    "train_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mMdb6S-VyycN",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read last 5 of train_data\n",
    "train_data.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yKpf_KoLyycQ"
   },
   "source": [
    "$\\quad$train_data is used for each row to display \"PassangerId\", \"Survived\", \"Pclass\", \"Name\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Ticket\", \"Embarked\" information. Here, 11 pieces of information except for \"Survived\" correspond to the feature, and \"Survived\" corresponds to the label.\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4NjcdTzpyycQ",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read first 5 of test_data\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-o5diRJAyycT",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read last 5 of test_data\n",
    "test_data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FyaSQxioyycW"
   },
   "source": [
    "$\\quad$If you look at test_data, you will see the following information from each row: \"PassangerId\", \"Pclass\", \"Name\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Ticket\", \"Fare\", \"Cabin\", \"Embarked\" are included. Unlike train_data, there is no \"Survived\" information corresponding to the label because test_data is data used to verify the model.\n",
    "<br>\n",
    "<br>\n",
    "$\\quad$As far as we can see, \"PassangerId\" is simply a feature that is attached for ordering and it is not necessary data to judge whether passennger is actually alive. And because \"Pclass\", \"Age\", \"SipSp\", \"Parch\", \"Fare\" are numeric information, machine learning algorithm can be applied even without preprocessing. However, other information such as \"Name\", \"Sex\", \"Ticket\", \"Cabin\", \"Embarked\" need appropriate preprocessing such as removing information and extracting new information before vectorization.\n",
    "<br>\n",
    "<br>\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZmfyfcN_yycW"
   },
   "source": [
    "$\\quad$Now, look at the distribution of given data, the relationship between survivability (\"Survived\"), and how to preprocess the data.\n",
    "<br>\n",
    "<br>\n",
    "$\\quad$First, let's look at the distribution of the numeric information in the data. Execute the following code to check the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nZLbwq3jyycX",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Analyze numeric information of train_data\n",
    "train_data.describe(percentiles=[0.25, 0.75])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S7xVWC88yyca"
   },
   "source": [
    "$\\quad$Note that, count(number of data), mean, std(standard deviation), min(minimum) the upper 25%, 50% 75% and max(maximum) are printed.\n",
    "<br>\n",
    "<br>\n",
    "$\\quad$For \"count\", the number of \"PassengerId\" is 891, so train_data contains a total of 891 people. For \"Age\", its count is 714, thus \"Age\" is not known for 177 passengers.\n",
    "<br>\n",
    "<br>\n",
    "$\\quad$Next is mean. You can see that average value of survival rate is 38.4%, ticket class is 2.3, number of sisters and brothers are 0.52 number of parents are 0.38 and the ticket cost is 32.2.\n",
    "<br>\n",
    "<br>\n",
    "$\\quad$The next values ​​are min, max, 25%, 50%, and 75%. These values allow us to understand the overall distribution and to make various interpretations. For example, \"SibSp\" and \"Parch\" are 1 or 0 in the top 75%, so most passengers boarded alone without a family. And up to 75% of the \"Fare\" was 31, but the max is 512, so some customers pay a lot more than other customers. If you want to know the value of the upper 60%, 80%, etc., you can change the value inside the percentile of the above code to 0.75, 0.8.\n",
    "<br>\n",
    "<br>\n",
    "$\\quad$The distribution of other information, except for the numeric information, can be seen by running the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wFWAO9Vfyyca",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Analyze non-numeric information of train_data\n",
    "train_data.describe(include=['O'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jb5gVTuKyycc"
   },
   "source": [
    "$\\quad$The code above shows the distribution of the non-numeric information \"Name\", \"Sex\", \"Ticket\", \"Cabin\", \"Embarked\". The output is \"count\" (number), \"unique\" (number of different information), \"top\" (top information), and \"freq\" (most frequent).\n",
    "<br>\n",
    "<br>\n",
    "$\\quad$For \"count\", train_data has a total of 891, so most information has 891 values. However, we can confirm that some portions of the information of \"Cabin\" and \"Embarked\" are unknown.\n",
    "<br>\n",
    "<br>\n",
    "$\\quad$For \"Unique\", \"Name\" has the value of 891, so everyone in train_data has a different name. There are two sexes, male and female, so it has a value of 2. Ticket and cabin are 681 and 147, respectively, and there are passengers with the same ticket or cabin number. Finally, since Titanic has three departing ports, so embarked is three.\n",
    "<br>\n",
    "<br>\n",
    "$\\quad$\"top\" is the most common information, and \"freq\" is the number of that information. Because \"Name\" is different for each person, freq is 1 and the value of top is not significant. \"Sex\" is 577 male, so there were 577 men and 314 women passengers. And if you look at \"Embarked\" you can see that most of the passengers (644) boarded at port \"S\" (Southampton).\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "$\\quad$Next, we examine how each of feature is related with \"Survived\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wyzdKdWsyycc",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Statistics between \"Pclass\" and \"Survived\"\n",
    "train_data[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WJbApXWYyyce"
   },
   "source": [
    "First, the relationship between \"Pclass\" and \"Survived\". The results show that the higher the ticket rating, the higher the survival rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4WNfYjPiyycf",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Statistics between \"Sex\" and \"Survived\"\n",
    "train_data[['Sex', 'Survived']].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EVlZ0eCmyych"
   },
   "source": [
    "The survival rate of women is much higher than that of men."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1-P8WW7qyych",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Statistics between \"SibSp\" and \"Survived\"\n",
    "train_data[['SibSp', 'Survived']].groupby(['SibSp'], as_index=False).mean().sort_values(by='Survived', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SvX-ZmjCyycj"
   },
   "source": [
    "\"SibSp\" is the number of brothers and sisters. In general, the lower the number of brothers and sisters shows the higher the survival rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8uiXdo3Myyck",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Statistics between \"Parch\" and \"Survived\"\n",
    "train_data[['Parch', 'Survived']].groupby(['Parch'], as_index=False).mean().sort_values(by='Survived', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-vrGStQxyycm"
   },
   "source": [
    "\"Parch\" is the number of parents and children. The lower the number, as in \"SibSp\" above, the higher the survival rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Co1yPa6gyycn",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Statistics between \"Embarked\" and \"Survived\"\n",
    "train_data[['Embarked', 'Survived']].groupby(['Embarked'], as_index=False).mean().sort_values(by='Survived', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OV3saplKyycp"
   },
   "source": [
    "\"Embarked\" is the boarding location. The survival rate is much higher than the other areas when the boarding location is \"C\", and is the lowest for \"S\" where the most people boarded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sapiAoO9yycp"
   },
   "source": [
    "$\\quad$\n",
    "\"Pclass\", \"Sex\" and \"Embarked\" are good features that can be directly related to \"Survived\". Also, you can use \"Sex\" and \"Embarked\" for training after vectorization of \"Sex\" and restoration of some unknown information of \"Embarked\".\n",
    "<br>\n",
    "<br>\n",
    "$\\quad$\"SibSp\" and \"Parch\", as we have seen above, tend to have a high survival rate when the number is small, but it is difficult to find a direct association. Therefore,we may apply the following preprocessing: '0' if the number is small (less or equal to 4) and '1' if it is big (more than 4). Since both of them indicate the number of family members, it is desirable to use \"FamilySize\" which is the sum of the two values ​​rather than using both of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kRSRn97Yyycp"
   },
   "source": [
    "## 2. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "Raz9jdtOyycq"
   },
   "source": [
    "$\\quad$First, we create a new feature called \"FamilySize\" by adding \"Sibsp\" and \"Parch\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "twL3VLTZyycq",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read Data\n",
    "(Code in tutorial video)\n",
    "\n",
    "# Add \"SibSp\" and \"Parch\" to make \"FamilySize\"\n",
    "(Code in tutorial video)\n",
    "\n",
    "# Delete \"SibSp\" abd \"Parch\"\n",
    "(Code in tutorial video)\n",
    "\n",
    "# Print top 5 values\n",
    "(Code in tutorial video)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f3PGNRVfyycs"
   },
   "source": [
    "As a result, \"SibSp\" and \"Parch\" are combined into one \"FamilySize\". Now let's look at the following code to see how this feature relates to \"Survived\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bGnHdBbfyyct",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Statistics between \"FamilySize\" and \"Survived\"\n",
    "(Code in tutorial video)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EnzVICe9yycv"
   },
   "source": [
    "To simplify further, we change each value of \"FamilySize\" to \"1\" if it is bigger than 4 and \"0\" if it is smaller than or equal to 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YPDe3lIsyycw",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Divide \"Family size\" into 0 and 1 based on 4\n",
    "(Code in tutorial video)\n",
    "\n",
    "# Print top 5 values\n",
    "(Code in tutorial video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oV2TDtQ7yycy",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Statistics between \"FamilySize\" and \"Survived\"\n",
    "(Code in tutorial video)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wuCAsKu3yyc3"
   },
   "source": [
    "\n",
    "$\\quad$\"Name\", \"Ticket\", and \"Cabin\" cannot be directly related to \"Survived\". Therefore, we may remove these three features.\n",
    "<br>\n",
    "<br>\n",
    "$\\quad$However, if you look at \"Name\", you find information such as 'Mr', 'Mrs', 'Capt', 'Master' and so on. We extract this information from \"Name\" and create a new feature \"Title\". After the extraction, \"Name\", \"Ticket\" and \"Cabin\" features are removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HgVSKur7yyc4",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Extract \"Name\" and create \"Title\"\n",
    "(Code in tutorial video)\n",
    "\n",
    "# Delete \"Name\", \"Ticket\", \"Cabin\" features\n",
    "(Code in tutorial video)\n",
    "\n",
    "# Print statistics of \"Title\"\n",
    "(Code in tutorial video)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rPpBm75syyc6"
   },
   "source": [
    "There are very few passengers with \"Title\" other than \"Master\", \"Mr\", \"Mrs\", and \"Ms\". So we replace these rare titles with \"Rare\" and titles for females such as \"MS\", \"Mlle\", and \"Mmn\" are combined with \"Miss\". After substitution, we vectorize 'Mr' to '1', 'Miss' to '2', 'Mrs' to '3', 'Master' to '4', 'Rare' to '5' and set '0' if \"Title\" is unknown. This can be done in the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-rLXpHRcyyc7",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The rest except the main \"Title\" is classified as \"Rare\"\n",
    "(Code in tutorial video)\n",
    "\n",
    "# Unify 'Ms', 'Mlle', 'Mme' as 'Miss'\n",
    "(Code in tutorial video)\n",
    "\n",
    "# \"Title\" vectorization\n",
    "(Code in tutorial video)\n",
    "\n",
    "# Set '0' for unknown \"Title\"\n",
    "(Code in tutorial video)\n",
    "\n",
    "# Print top 5 values\n",
    "(Code in tutorial video)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6QCmIDJ8yyc9"
   },
   "source": [
    "\n",
    "$\\quad$In case of \"Age\", there are 177 missing data and we restore them by the average age (30) of the rest of the passengers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yh0e4Yuxyyc-",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Restore empty part to average age\n",
    "(Code in tutorial video)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-8uNcvIwyyc0"
   },
   "source": [
    "# DIY: Preprocessing\n",
    "$\\quad$(pause the video and complete this part!)\n",
    "<br>\n",
    "<br>\n",
    "$\\quad$\"Sex\" and \"Embarked\" are information that directly affects \"Survived\". Therefore, these two pieces of information do not require any preprocessing; we simply restore the missing parts and run vectorization.\n",
    "<br>\n",
    "<br>\n",
    "$\\quad$First, we restore the two lost data of \"Embarked\". In this preproessing, we would like to designate two \"Embakred\" information as 'S' port where the most passengers have boarded. Then, we set 'female' of 'Sex' to '0', and '1' to 'male', 'Q', 'C', 'S' of 'Embarked' are set to '0' 1 'and' 2 ', respectively. You can do these in the code below.\n",
    "<br>\n",
    "<br>\n",
    "$\\quad$**Fill in the '???' part!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GVqm2E0myyc1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 1. Fill unknown \"Embarked\" to 'S'\n",
    "# >> Which data do we want to edit?\n",
    "# >> The unknown data is labeled as None, and we want to replace them with 'S'.\n",
    "# (Hint: The code is almost same as the cell right above!!!)\n",
    "preprocessing_train_data[???].replace(???)\n",
    "preprocessing_test_data[???].replace(???)\n",
    "\n",
    "# 2. \"Embarked\", \"Sex\" vectorization\n",
    "# >> To apply Logistic regression or SVM,\n",
    "#    we want to convert features that are in string format into numeric values.\n",
    "# >> Let's replace 'female' --> 0, 'male' --> 1\n",
    "preprocessing_train_data.replace(['female', 'male'], [0, 1], inplace=True)\n",
    "\n",
    "# >> Now, replace 'Q' --> 0, 'C' --> 1, 'S' --> 2 in the same way!\n",
    "preprocessing_train_data.replace(???)\n",
    "\n",
    "# >> We also need to vectorize the test set.\n",
    "# >> 'female' --> 0, 'male' --> 1\n",
    "preprocessing_test_data.replace(???)\n",
    "# >> 'Q' --> 0, 'C' --> 1, 'S' --> 2\n",
    "preprocessing_test_data.replace(???)\n",
    "\n",
    "# Print top 5 values\n",
    "preprocessing_train_data[['Sex', 'Embarked']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ywuzWPdAyydA",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print result\n",
    "preprocessing_train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_0J8AsCRyydD"
   },
   "source": [
    "The results contain 7 features which are \"Title\", \"Pclass\", \"Sex\", \"Age\", \"Fare\", \"Embarked\", \"FamilySize\". Note that \"Age\" and \"Fare\" need proper normalization. Perform \"standardization\" for these two features.\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GgrQiOqAyydD"
   },
   "source": [
    "## 3. Machine Learning\n",
    "$\\quad$Now we apply machine learning algorithms to preprocessed data. In this project, we will use 'Logistic Regression', and 'SVM'.\n",
    "<br>\n",
    "<br>\n",
    "$\\quad$To use each algorithm, we create training data by removing \"Survived\" and meaningless \"PassangerId\" from preprocessed data, and extract only \"Survived\" to create label data, (remove \"PassagerId\" from the test data), apply each algorithm, predict the test data with the resulting model. The code is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HNuOdspKyydE",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating data for training\n",
    "(Code in tutorial video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1uh7YBpPyydH",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classifier = (Code in tutorial video)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "(Code in tutorial video)\n",
    "\n",
    "# Check the accuracy, AUC, and ROC curve of the classifier set above\n",
    "(Code in tutorial video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YSf-xZRxyydJ"
   },
   "outputs": [],
   "source": [
    "# Test data prediction\n",
    "(Code in tutorial video)\n",
    "\n",
    "# This is how the model predicted\n",
    "(Code in tutorial video)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DG3NkEwwEKsG"
   },
   "source": [
    "# DIY: SVM classifier\n",
    "$\\quad$Now, you can do the same thing with SVM. Apply SVM to the training data and check the result.\n",
    "<br>\n",
    "<br>\n",
    "$\\quad$**Fill in the '???' part!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qlg0WuCLAGCC",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 1. Create a SVM classifier from scikit-learn:\n",
    "#    remember that we imported SVC from sklearn.svm!\n",
    "# (Note: you need to set 'probability' argument to True)\n",
    "classifier = ???\n",
    "\n",
    "# >> Train the classifier with the training set we preprocessed.\n",
    "# >> Use fit() method.\n",
    "classifier.???(???)\n",
    "\n",
    "# >> Check the model accuracy on training set\n",
    "# >> You can get the mean accuracy of a given dataset and labels\n",
    "#    with score() method\n",
    "accuracy = classifier.???(???) * 100\n",
    "\n",
    "# 2. Draw ROC curve on training set\n",
    "# >> First, you need to compute probabilities of each labels for training set.\n",
    "#    (which means you need to make *model predictions* for training set)\n",
    "# >> You can do this with predict_proba() method\n",
    "Y_train_pred = classifier.???(???)[:, 1]\n",
    "\n",
    "# >> Calculate false positive rates, true positive rates,\n",
    "#    and area under the curve (AUC) with\n",
    "#    ground truth labels & predicted probability\n",
    "FPR, TPR, thresholds = roc_curve(???)\n",
    "AUC = roc_auc_score(???)\n",
    "\n",
    "# Plot ROC curve.\n",
    "# (hint: use plt.plot() to plot FPR and TPR)\n",
    "???(???)\n",
    "\n",
    "print(\"Accuracy: \", \"{0:.2f}\".format(accuracy))\n",
    "print(\"Area Under the Curve: \", \"{0:.2f}\".format(AUC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m2xyxzv2AKhK"
   },
   "outputs": [],
   "source": [
    "# Test data prediction\n",
    "predict = classifier.predict(???)\n",
    "predict = np.round(predict)\n",
    "\n",
    "# This is how the model predicted\n",
    "result = test_data.copy()\n",
    "result[\"PREDICTION\"] = predict\n",
    "result.head()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "Assignment5_student.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
